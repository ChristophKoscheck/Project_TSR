# -*- coding: utf-8 -*-
"""Traffic Signs HSPF Master 2024

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nm2AaQ7du7ZNS0gcghh2hnbJHDTRF9i1

# TensorFlow Traffic Sign Recognition (Belgian Traffic Sign data set)
"""
import wget
wget.download("https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip")
wget.download("https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip")

import zipfile
# !unzip BelgiumTSC_Training.zip
# !unzip BelgiumTSC_Testing.zip
# Specify the path to the zip file
train_path = "./BelgiumTSC_Training.zip"
test_path = "./BelgiumTSC_Testing.zip"

# Open the zip file
with zipfile.ZipFile(train_path, 'r') as zip_ref:
    # Extract all the contents of the zip file to the specified extract path
    zip_ref.extractall()
# Open the zip file
with zipfile.ZipFile(test_path, 'r') as zip_ref:
    # Extract all the contents of the zip file to the specified extract path
    zip_ref.extractall()


import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

import os
import numpy as np
import random

from skimage import transform
from skimage import data
from skimage.color import rgb2gray
from imageio.v2 import imread

# Create a dictionary with Class Names
classnames = {
              0 : 'Warning for a bad road surface',
              1 : 'Warning for a speed bump',
              2 : 'Warning for a slippery road surface',
              3 : 'Warning for a curve to the left',
              4 : 'Warning for a curve to the right',
              5 : 'Warning for a double curve, first left then right',                                                    # Merge Classes 5 & 6 later
              6 : 'Warning for a double curve, first left then right',
              7 : 'Watch out for children ahead',
              8 : 'Watch out for  cyclists',
              9 : 'Watch out for cattle on the road',
              10: 'Watch out for roadwork ahead',
              11: 'Traffic light ahead',
              12: 'Watch out for railroad crossing with barriers ahead',
              13: 'Watch out ahead for unknown danger',
              14: 'Warning for a road narrowing',
              15: 'Warning for a road narrowing on the left',
              16: 'Warning for a road narrowing on the right',
              17: 'Warning for side road on the right',
              18: 'Warning for an uncontrolled crossroad',
              19: 'Give way to all drivers',
              20: 'Road narrowing, give way to oncoming drivers',
              21: 'Stop and give way to all drivers',
              22: 'Entry prohibited (road with one-way traffic)',
              23: 'Cyclists prohibited',
              24: 'Vehicles heavier than indicated prohibited',
              25: 'Trucks prohibited',
              26: 'Vehicles wider than indicated prohibited',
              27: 'Vehicles higher than indicated prohibited',
              28: 'Entry prohibited',
              29: 'Turning left prohibited',
              30: 'Turning right prohibited',
              31: 'Overtaking prohibited',
              32: 'Driving faster than indicated prohibited (speed limit)',
              33: 'Mandatory shared path for pedestrians and cyclists',
              34: 'Driving straight ahead mandatory',
              35: 'Mandatory left',
              36: 'Driving straight ahead or turning right mandatory',
              37: 'Mandatory direction of the roundabout',
              38: 'Mandatory path for cyclists',
              39: 'Mandatory divided path for pedestrians and cyclists',
              40: 'Parking prohibited',
              41: 'Parking and stopping prohibited',
              42: '',
              43: '',
              44: 'Road narrowing, oncoming drivers have to give way',
              45: 'Parking is allowed',
              46: 'parking for handicapped',
              47: 'Parking for motor cars',
              48: 'Parking for goods vehicles',
              49: 'Parking for buses',
              50: 'Parking only allowed on the sidewalk',
              51: 'Begin of a residential area',
              52: 'End of the residential area',
              53: 'Road with one-way traffic',
              54: 'Dead end street',
              55: '',
              56: 'Crossing for pedestrians',
              57: 'Crossing for cyclists',
              58: 'Parking exit',
              59: 'Information Sign : Speed bump',
              60: 'End of the priority road',
              61: 'Begin of a priority road'
    }

"""<a id='exploration'></a>
## Loading And Exploring The Data
"""

def load_data(data_dir):
    # Get all subdirectories of data_dir. Each represents a label.
    directories = [d for d in os.listdir(data_dir)
                   if os.path.isdir(os.path.join(data_dir, d))]
    # Loop through the label directories and collect the data in
    # two lists, labels and images.
    labels = []
    images = []
    for d in directories:
        label_dir = os.path.join(data_dir, d)
        file_names = [os.path.join(label_dir, f)
                      for f in os.listdir(label_dir)
                      if f.endswith(".ppm")]
        for f in file_names:
            images.append(imread(f))
            labels.append(int(d))
    return images, labels

ROOT_PATH = ""
train_data_dir = os.path.join(ROOT_PATH, "Training")
test_data_dir = os.path.join(ROOT_PATH, "Testing")

train_images, train_labels = load_data(train_data_dir)
test_images, test_labels = load_data(test_data_dir)

train_labels_array = np.array(train_labels)
test_labels_array = np.array(test_labels)

train_images[1351]

train_labels_array = np.array(train_labels)
test_labels_array = np.array(test_labels)

train_images_array = train_images
test_images_array = test_images
# Print the `images` dimensions
#print(train_images_array.ndim)

# Print the number of `images`'s elements
print(len(train_images_array))

# Print the first instance of `images`
train_images_array[0]

# Print the `labels` dimensions
print(train_labels_array.ndim)

# Print the number of `labels`'s elements
print(train_labels_array.size)

# Count the number of labels
print(len(set(train_labels_array)))

# Import the `pyplot` module
import matplotlib.pyplot as plt

# Make a histogram with 62 bins of the `labels` data
plt.hist(train_labels, 62)

# Show the plot
plt.show()

# Import the `pyplot` module
import matplotlib.pyplot as plt

# Make a histogram with 62 bins of the `labels` data
plt.hist(test_labels, 62)

# Show the plot
plt.show()

# Import the `pyplot` module of `matplotlib`
import matplotlib.pyplot as plt

# Determine the (random) indexes of the images that you want to see
traffic_signs = [300, 2250, 3650, 4000]

# Fill out the subplots with the random images that you defined
for i in range(len(traffic_signs)):
    plt.subplot(1, 4, i+1)
    plt.axis('off')
    plt.imshow(train_images[traffic_signs[i]])
    plt.subplots_adjust(wspace=0.5)

plt.show()

# Import `matplotlib`
import matplotlib.pyplot as plt

# Determine the (random) indexes of the images
traffic_signs = [300, 2250, 3650, 4000]

# Fill out the subplots with the random images and add shape, min and max values
for i in range(len(traffic_signs)):
    plt.subplot(1, 4, i+1)
    plt.axis('off')
    plt.imshow(train_images[traffic_signs[i]])
    plt.subplots_adjust(wspace=0.5)
    plt.show()
    print("shape: {0}, min: {1}, max: {2}".format(train_images[traffic_signs[i]].shape,
                                                  train_images[traffic_signs[i]].min(),
                                                  train_images[traffic_signs[i]].max()))

"""<a id='extraction'></a>
## Feature Extraction
### Rescaling Images
"""

# Resize images
import skimage                              # for scikit-learn image operations
def transform_images(images,height,width):
  transformed_images = [skimage.transform.resize(image,(height,width)) for image in images]
  return transformed_images
train_images128 = transform_images(train_images,128,128)
train_images128 = np.array(train_images128)
test_images128 = transform_images(test_images,128,128)
test_images128 = np.array(test_images128)

"""### Image Conversion to Grayscale"""

def convert_to_grayscale(images_array):
  return skimage.color.rgb2gray(images_array)

train_images128_gray = convert_to_grayscale(train_images128)
print(train_images128_gray[0].shape)

#images32 = convert_to_grayscale(np.array(images32))

def image_dims(images):
  heights = []
  widths =  []
  min_height = images[0].shape[0]
  min_width =  images[0].shape[1]
  for img in images:
    heights.append(img.shape[0])
    widths.append(img.shape[1])
    if min_height > img.shape[0]:
      min_height = img.shape[0]
    if min_width  > img.shape[1]:
      min_width= img.shape[1]
  print('Min Height:',str(min_height))
  print('Min Width:',str(min_width))
  return heights,widths

def plot_dimensions(dimension, count,text = 'Dimension'):
  print('maximum amount of images with '+ text +' {0} := {1}'.format(list(dimension)[list(count).index(max(count))],max(count)))
  plt.scatter(list(dimension),count)
  plt.title("Image Height Distrbution")
  plt.xlabel('Dimension')
  plt.ylabel('Number of Images')
  plt.show()

heights,widths = image_dims(train_images)
unique_heights = set(heights)
unique_widths = set(widths)

heights_count = [heights.count(num) for num in unique_heights]
widths_count = [widths.count(num) for num in unique_widths]

plot_dimensions(unique_heights,heights_count,'Height')
plot_dimensions(unique_widths,widths_count,'Width')

# Training Data Generator

training_datagen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2,width_shift_range=0.3,height_shift_range=0.2,shear_range=0.25,fill_mode='nearest')
train_generator = training_datagen.flow(train_images128,train_labels,batch_size=32)

def conv_net(train_images_dims,num_of_classes,filter_size = 2,num_convolutions=64,num_strides=2):
  # pre process image dimensions
  if (len(train_images_dims) == 3):    # Channel Last
    train_images_dims = (train_images_dims[1],train_images_dims[2])
  elif (len(train_images_dims) == 4):
    train_images_dims = (train_images_dims[1],train_images_dims[2],train_images_dims[3])

  model  = tf.keras.Sequential()

  #Conv1
  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu',input_shape= train_images_dims))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))

  #Conv2
  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu'))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))

  #Conv3
  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu'))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))

  #Conv4
  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu'))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))

  #Conv5
  model.add(tf.keras.layers.Conv2D(int(num_convolutions) ,(filter_size,filter_size),activation='relu'))
  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))

  #Flatten and add Dense Layer
  model.add(tf.keras.layers.Flatten())
  #Dense 1
  model.add(tf.keras.layers.Dense(512,activation='relu'))
  model.add(tf.keras.layers.Dropout(0.5))
  #Dense 2
  model.add(tf.keras.layers.Dense(512,activation='relu'))
  model.add(tf.keras.layers.Dropout(0.5))

  #Output Layer
  model.add(tf.keras.layers.Dense(num_of_classes,activation = 'softmax'))
  return model

monitor = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 8,restore_best_weights = True, min_delta = 0.01)

model_regularized = conv_net(train_images128.shape,len(set(train_labels)),filter_size=2,num_convolutions=512)

model_regularized.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics = ['accuracy'])
model_regularized.summary()

"""### Running The Neural Network"""

history = model_regularized.fit(train_generator, validation_data=train_generator,steps_per_epoch=(len(train_images) / 32),epochs = 15,verbose=1,callbacks=[monitor])  # 32 = batch size

"""### Evaluating The Neural Network"""

# Get training and test loss histories
training_loss = history.history['loss']
validation_loss = history.history['val_loss']

# Create count of the number of epochs
epoch_count = range(1, len(training_loss) + 1)

# Visualize loss history
plt.plot(epoch_count, training_loss, 'r--')
plt.plot(epoch_count, validation_loss, 'b-')
plt.legend(['Training Loss', 'Validation Loss'])
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

# SAVE THE MODEL AS H5 File (e.g. to use in an app)
model_regularized.save('final_model.h5')